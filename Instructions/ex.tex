\documentclass[a4paper]{article}
\usepackage{a4wide,latexsym,epsfig,color,xspace}
\usepackage{xspace}

\usepackage{wrapfig}


\usepackage{tikz}
\usetikzlibrary{automata}
\usetikzlibrary{arrows}
\usetikzlibrary{shapes}
\tikzstyle{every picture}=[thick]
\tikzstyle{every scope}=[>=latex, node distance=2.3cm]
\tikzstyle{st} = [state, ellipse, minimum size=4mm, inner sep=0.5mm, node distance=2.3cm]


\newcommand{\JTORX}[0]{\textsc{JTorX}\xspace}
\newcommand{\IOCO}[0]{{\ensuremath{\mathbf{ioco}}}\xspace}
\newcommand{\UIOCO}[0]{{\ensuremath{\mathbf{uioco}}}\xspace}
\newcommand{\FAIL}[0]{{\ensuremath{\mathbf{fail}}}\xspace}
\newcommand{\YED}[0]{\textsc{yEd}\xspace}

\newcounter{commentcounter}
\newcommand{\XXX}[1]{%
%  \refstepcounter{commentcounter}%
  \stepcounter{commentcounter}%
  {\footnotesize\bf$^{(\arabic{commentcounter})}$}%
  \marginpar{%
    \footnotesize({\bf{\arabic{commentcounter}}})%
    \footnotesize{#1}%
  }%
}

\usepackage{tweaklist}
\renewcommand{\itemhook}{\setlength{\itemsep}{0pt}
%\setlength{\topsep}{0pt}
}
\renewcommand{\descripthook}{\setlength{\itemsep}{0pt}\setlength{\topsep}{0pt}}

\renewcommand{\enumhook}{\setlength{\itemsep}{0pt}\setlength{\partopsep}{0pt}\setlength{\parsep}{0pt}}

%\setlength{\textwidth}{14.9cm}

%\setlength{\oddsidemargin}{1.1cm}
%\setlength{\evensidemargin}{1.1cm}
%\setlength{\topmargin}{0.9cm}
%\setlength{\headsep}{0.0cm}
%\setlength{\textheight}{22cm}
%\setlength{\textwidth}{13.5cm}
%\setlength{\parindent}{0mm}
%\setlength{\parskip}{0.666\baselineskip}
%\setlength{\topsep}{0mm}
%\setlength{\itemsep}{0mm}
%\setlength{\abovedisplayskip}{0mm}
%\setlength{\belowdisplayskip}{0mm}
%\setlength{\abovedisplayshortskip}{0mm}
%\setlength{\belowdisplayshortskip}{0mm}

\usepackage{thumbpdf}
\usepackage[bookmarksnumbered,plainpages,backref,hidelinks]{hyperref}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\title{Automata learning with Learnlib}

\author{David Huistra \and Jeroen Meijer}

\date{March 7, 2017}
% \author{Jeroen Meijer (j.j.g.meijer@utwente.nl) \\ \footnotesize{Original author: Axel Belinfante}}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

% links:
% game animated with flash http://www.plastelina.net/game1.html
% folklore http://www.folklore.ee/Folklore/vol35/voolaid.pdf
% other game http://freeweb.siol.net/danej/riverIQGame.swf

\newcommand{\deadline}{\emph{February 16, 2016, 8:45 hours}\xspace}

\begin{document}

%\pagestyle{empty}
\maketitle
%\thispagestyle{empty}
% \vspace{1.5\baselineskip}

\section*{Introduction}
% \begin{abstract}
%\textbf{Important: login to the lab computers using course code 217001.}
The goal of this assignment is to get some hands on experience with automata learning. First you will learn a model of your own implementation, to show it is relatively easy to use Learlib for automata learning. After that you will experiment with the learning process to see how the performance of the process can be increased, for example by using different learning algorithms or a caching mechanism. Finally we will show how the learned model of an implementation can be used to test the implementation by using LTSMin for model checking.

% Note that this assignment requires you to upload a mutant implementation of WGCF
% before the lab class on \deadline.
% \end{abstract}

\section*{Preliminaries: Installing stuff.}

\paragraph{Optional: Install GraphViz}
The Learnlib provides the option to export the learned models to the GraphDOT format so that they can visualized by the GraphViz application. If you want to visualize the learned models (reccomended), you need to install GraphViz. This can be done from here: \url{http://www.graphviz.org/Download..php}. If you do not install GraphViz, you will see the models in the (textual) GraphDot format.

\emph{Sidenote: For Windows users, please be aware that you will need to add GraphViz to your PATH variable (as explained on the download page, but easily looked over).}

\paragraph{Optional: Install Eclipse}
For this assignment you will need to include one or two jar libraries into your code. We therefore recommend that you use a java IDE. Specifically we will provide support for Eclipse throughout this document, but you are free to use another IDE such as InteliJ or use a text editor and command line.



\section*{Part 1. Learning a model of your Wolf-Goat-Cabbage implementation}

\textbf{The assignment}. We will start off this assignment by automatically learning a model of your Wolf-Goat-Cabbage implementation. We will provide you with some basic Learnlib settings for this task. The only task you will need to perform is to write a wrapper for your implementation so that Learnlib will know how to interact with it.  This will be done by implementing Learnlib's SUL interface.

\textbf{Download the Learnlib setup}. Download the provided basic framework from GitHub\footnote{\url{https://github.com/djhuistra/tt-learnlib-practicum}} as a Zip file and extract it on your file system (or clone with git). In addition to a basic Learnlib setup (the learner class and the (empty) SUL wrapper class), this also includes a .jar library with the entire Learnlib project.

\textbf{Eclipse instructions} Setting up the project in Eclipse. In eclipse, create a new Java project and select the folder of the extracted Learlib framework as the root of the project. Otherwise you can create a new Java project and import the files. Next you will have to include the jar file as a project library: right click project name  -\textgreater properties  -\textgreater Java Build Path -\textgreater Add External JARs -\textgreater Select the Learnlib jar in the lib folder.

\medskip
At this point: Make sure that you can successfully run the learner. It should return a model with only one state, as the wrapper has not yet been implemented.

\emph{Sidenote. In the learner class indicate if you have installed graphDOT, so it will produce a graphical model.}

\medskip
\textbf{Getting to work}. Now you may start with implementing the SUL wrapper for your WGC implementation. While it is possible to learn a complete black-box implementation, we advice you to use a glass-box implementation and use. For this, we advice you to use your WGC implementation as a library jar, not as a runnable jar. In this way can import and use the implemented WGC Model class in your WGCSUL implementation. The empty WGCSUL class also provides some suggestions. Note that in this lab we will not be using the binary encoding of inputs and outputs. 

We assume the same input and outputs as used in the lecture. So the inputs are one of the set \{"cabbage?", "goat?", "nothing?", "wolf?"\} and each input should return a response that is contained in the set \{"eaten!", "finished!", "init!", "ok!", "retry!"\}. Note that the "ok!" output is new, i.e. we did not see this output in the IOCO lab.

\medskip
\textbf{Eclipse instructions} Include your Wolf-Goat-Cabbage implementation into the project (Including a jar file in eclipse: right click project name-\textgreater properties  -\textgreater Java Build Path  -\textgreater  Add External JARs  -\textgreater  Select implementation jar).



\section*{Part 2. \texttt{SUL} Wrapping}
While it is pretty cool to be able to learn a model by interacting with an implementation, the success of this method depends in practice also on its performance. Is it still feasible to learn the model of a larger implementation in a reasonable amount of time? Increasing the performance of this method is currently an active area of research.

In this part we want you to get some insight into one of the bottlenecks of the process: interaction with the SUL. Each interaction with the SUL is considered expensive, and therefore if possible we want to limit the amount of interaction.
 
\medskip
First we want to gain some insight into the interaction taking place in the learning process. Therefore we want to wrap our \texttt{SUL} in a \texttt{SymbolCounterSUL}\footnote{\url{https://github.com/LearnLib/learnlib/blob/develop/core/src/main/java/de/learnlib/oracles/SymbolCounterSUL.java}} that counts the number of total steps taken during the learning process, and then pass this \texttt{SymbolCounterSUL} to the membershipOracle. After the experiment, obtain the data using the \texttt{getStatisticalData()} method. Observe the output.

\medskip
Now we want to see if we can improve this. Learnlib offers a caching mechanism for SULs that might just help. Read the documentation to see what the cache wrapper\footnote{\url{https://github.com/LearnLib/learnlib/blob/develop/filters/cache/src/main/java/de/learnlib/cache/sul/SULCache.java}} does:


Since \texttt{SULCache}'s constructor method is deprecated, we recommend that you use the \texttt{createCache()} method from the \texttt{SULCaches}\footnote{\url{https://github.com/LearnLib/learnlib/blob/develop/filters/cache/src/main/java/de/learnlib/cache/sul/SULCaches.java}} class to wrap your \texttt{SUL} with this caching mechanism. 


Think about whether you should wrap the \texttt{SUL} directly or whether you should wrap the \texttt{SymbolCounterSUL}. Hint: the \texttt{SymbolCounterSUL} counts every call of the \texttt{step()} method before it passes on the call to the \texttt{SUL} it wraps. If you cannot determine the correct order, you can always experiment to find out :)

See if, after wrapping the \texttt{SUL} in a cache, you can notice a significant change in the number of executed steps.

\section*{Part 3. Learning Experiment}
For this part of the assignment you will experiment with different learning algorithms and hypothesis testing methods. To save you from the bulk of the work of setting this experiment up with Learnlib, the experiments setup is given, based on a slightly modified version borrowed from RU Nijmegen\footnote{\url{https://gitlab.science.ru.nl/ramonjanssen/basic-learning}}. 

This code can be found in the part3 folder of the github repo. You should directly be able to run the experiment using the Experiment\_Main class.

In this setup, the experiment is given the learning algorithm and hypothesis testing method as parameters. These enum parameters can easily be changed between runs of the experiments. In this assignment it is your task to fiddle around with these to find the optimal combination. Perform this task for both the ExperimentSUL included in the experiment and your own WGCFSUL. 

\begin{itemize}
     \item What is the fastest \emph{learning} algorithm? 
     \item What is the fastest \emph{testing} algorithm? 
     \item What is the minimum value for \texttt{maxDepth} in the \texttt{WMethodEQOracle}/\texttt{WpMethodEQOracle} that still gives you a correct final hypothesis?
     \item How well does the \texttt{RandomWalkEQOracle} perform with different parameters?
\end{itemize}

\section*{Part 4. Model checking}
In this section we will show how a learned automaton can be checked for correctness, through Linear Temporal Logic (LTL).
\begin{enumerate}
     \item     The LearnLib itself is not capable of model checking a learned automaton, therefore we are going to use LTSmin.
               LTSmin requires a Mealy machine specified in \texttt{ETF} format. 
               In addition to \texttt{.dot} files, you can also export \texttt{.etf}, by adding to \texttt{Experiment\_Learner.produceOutput()},
               the following piece of code:
               
               \texttt{PrintWriter etfWriter = new PrintWriter(fileName + ".etf"); \\
                       ETF.export(model, alphabet, etfWriter); \\
                       etfWriter.close();}.
     \item     The LTSmin binaries that have been made available on Blackboard (Assignments \textgreater{} Lab \textgreater{} LTSmin) are currently only available on Linux.
               If you are not using Linux, the easiest way to get started is to download VirtualBox\footnote{\url{https://www.virtualbox.org/}}, and download a Linux virtual
               machine from \url{http://www.osboxes.org/}. Installing VirtualBox guest additions is recommended for quickly moving files (such as \texttt{.etf}) between the host and the guest.
               To do so, make sure to enable the bi-directional clip board (via \emph{Devices} in the top menu of the VM).
     \item     To instantiate the state space of a learned automaton, open up a Linux terminal, run \texttt{./etf2lts-seq learnedModel.etf}.
               This should show \texttt{state space 8 levels, 9 states 36 transitions}.
     \item     To model check an automaton add the \texttt{--ltl} option, e.g. to check the requirement ``\emph{The game can only be finished while moving the goat}'', run
               \texttt{./etf2lts-seq learnedModel.etf --ltl='[](output == "finished!" -> input == "goat?")'}.
     \item     To verify that no counter example has been found run \texttt{echo \$?}, this returns the exit code of the last command line; \texttt{0} means
               no counter example, \texttt{1} means a counter example has been found.
     \item     To show a counter example you can for example run \texttt{./etf2lts-seq learnedModel.etf --ltl='[](output == "finished!" -> input == "nothing?")'}
               (the game can only be finished while moving nothing). The commandline \texttt{echo \$?} should show \texttt{1}. To write the counter example
               to disk, add the option \texttt{--trace="/tmp/trace.gcf"}, 
               e.g. \texttt{./etf2lts-seq learnedModel.etf --ltl='[](output == "finished!" -> input == "nothing?")' \\ --trace=/tmp/trace.gcf}.
               To print the counter example, run \texttt{./ltsmin-printtrace /tmp/trace.gcf}. Aside from some verbose output, you should be able to recognize the
               inputs and outputs in the trace. As a last remark note that LTSmin will always try to find infinite traces. This is shown in the trace as a self loop, in the
               very last transition.
     \item     If you want to write your own LTL formula, note that you should encapsulate the formula in single quotes. Strings (such as "eaten!") should have double quotes.
               The Future and Globally operator are written as \texttt{<>} and \texttt{[]} respectively, and the implication as \texttt{->}.
               For more LTL operators please refer to \url{http://jmeijer.nl/ltsmin/assets/man/ltsmin-ltl.html}.
     \item     Can you spot (or prove) errors (or their absence) in WGCF implementations of other students, using active learning and model checking? The student mutants can be found on Blackboard
               (assignments \textgreater{} Lab \textgreater{} student mutants).
\end{enumerate}

\end{document}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%